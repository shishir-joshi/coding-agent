# Tiny Tool-Using LLM Agent (Learning Project)

A very small CLI "agent" that:
- Chats with you in a REPL
- Calls tools (read files, search, write files)
- Applies patches (diff-style edits)
- Can print its current context/messages
- Saves a basic history log

## Quickstart

1) Set env vars:

- `OPENAI_API_KEY` (required)
- `OPENAI_MODEL` (optional, default: `gpt-4o-mini`)
- `OPENAI_BASE_URL` (optional, default: `https://api.openai.com/v1`)

2) Run:

```bash
python3 -m agent
```

## REPL commands

- `/help` – show help
- `/context` – print the current LLM message context (system + conversation + tool outputs)
- `/history [n]` – show last n turns from the on-disk history log (default 10)
- `/reset` – clears in-memory context (does not delete history log)
- `/exit` – quit

## Notes

- This project intentionally avoids fancy features (streaming UI, embeddings, vector DBs, etc.).
- The patch tool is intentionally simple: it’s designed for patches *generated by the agent itself*.
